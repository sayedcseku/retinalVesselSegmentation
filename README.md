<div align="center">

# ğŸ”¬ Retinal Blood Vessel Segmentation from Color Fundus Images

[![MATLAB](https://img.shields.io/badge/MATLAB-R2016b+-FF6F00?style=for-the-badge&logo=mathworks&logoColor=white)](https://www.mathworks.com/products/matlab.html)
[![Python](https://img.shields.io/badge/Python-3.7+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-00C853?style=for-the-badge&logo=open-source-initiative&logoColor=white)](LICENSE)

[![IET Paper](https://img.shields.io/badge/ğŸ“„_IET_Journal-2021-D32F2F?style=for-the-badge)](https://ietresearch.onlinelibrary.wiley.com/journal/17519667)
[![AIME Conference](https://img.shields.io/badge/ğŸ“_AIME_Conference-2019-1976D2?style=for-the-badge)](#-publications)
[![IbPRIA Conference](https://img.shields.io/badge/ğŸ“_IbPRIA_Conference-2019-7B1FA2?style=for-the-badge)](#-publications)

[![Datasets](https://img.shields.io/badge/ğŸ“Š_Datasets-DRIVE_|_STARE_|_CHASE--DB1-00BCD4?style=for-the-badge)](#-supported-datasets)
[![Code Quality](https://img.shields.io/badge/Code_Quality-Production_Ready-4CAF50?style=for-the-badge)](#-installation)

</div>

---

### ğŸš€ *Next-generation retinal vessel segmentation powered by ensemble machine learning and deep neural networks*

<div align="center">

| ğŸ¤– **Machine Learning** | ğŸ§  **Deep Learning** | ğŸ­ **Ensemble Methods** | ğŸ”¬ **Advanced Features** |
|:------------------------:|:---------------------:|:------------------------:|:-------------------------:|
| [![RF](https://img.shields.io/badge/Random_Forest-Available-success?style=flat-square)](src/classification/trainRFC.m) | [![Deep Features](https://img.shields.io/badge/CNN_Features-VGG--16-informational?style=flat-square)](src/python/) | [![Majority Voting](https://img.shields.io/badge/Majority_Voting-âœ“-success?style=flat-square)](src/classification/trainEnsemble.m) | [![Binary 32](https://img.shields.io/badge/32--bit_Binary-âœ“-blue?style=flat-square)](src/features/create_binary_32.m) |
| [![SVM](https://img.shields.io/badge/SVM_(RBF/Linear)-Available-success?style=flat-square)](src/classification/trainSVM.m) | [![Patch Extraction](https://img.shields.io/badge/Adaptive_Patches-Available-informational?style=flat-square)](src/python/patch_extraction.py) | [![Weighted Voting](https://img.shields.io/badge/Weighted_Voting-âœ“-success?style=flat-square)](src/classification/testEnsemble.m) | [![Binary 64](https://img.shields.io/badge/64--bit_Binary-âœ“-blue?style=flat-square)](src/features/create_binary_64.m) |
| [![AdaBoost](https://img.shields.io/badge/AdaBoost-Available-success?style=flat-square)](src/classification/trainAdaBoost.m) | [![Transfer Learning](https://img.shields.io/badge/Transfer_Learning-Pre--trained-informational?style=flat-square)](src/python/) | [![Stacking](https://img.shields.io/badge/Meta_Stacking-âœ“-success?style=flat-square)](src/classification/trainEnsemble.m) | [![Binary 128](https://img.shields.io/badge/128--bit_Binary-âœ“-blue?style=flat-square)](src/features/create_binary_128.m) |
| | | | [![Binary 512](https://img.shields.io/badge/512--bit_Binary-âœ“-blue?style=flat-square)](src/features/create_binary_512.m) |

</div>

---

### ğŸ† **Benchmark Performance Results**

<div align="center">

*ğŸ¯ **Clinical-grade accuracy** achieved through advanced ensemble intelligence and multi-dimensional feature engineering*

<table>
<tr>
<th align="center">ğŸ—ƒï¸ <strong>Dataset</strong></th>
<th align="center">ğŸ¯ <strong>Accuracy</strong></th>
<th align="center">ğŸ” <strong>Sensitivity</strong></th>
<th align="center">âš¡ <strong>Specificity</strong></th>
<th align="center">ğŸ“Š <strong>AUC</strong></th>
<th align="center">ğŸ… <strong>Top Method</strong></th>
<th align="center">â±ï¸ <strong>Processing</strong></th>
</tr>
<tr>
<td align="center"><strong>ğŸ”´ DRIVE</strong></td>
<td align="center"><code>ğŸŸ¢ 96.1%</code></td>
<td align="center"><code>ğŸŸ¡ 78.5%</code></td>
<td align="center"><code>ğŸŸ¢ 98.4%</code></td>
<td align="center"><code>ğŸŸ¢ 88.9%</code></td>
<td align="center">ğŸ­ <strong>Ensemble</strong></td>
<td align="center"><code>~15s/img</code></td>
</tr>
<tr>
<td align="center"><strong>ğŸŸ  STARE</strong></td>
<td align="center"><code>ğŸŸ¢ 95.6%</code></td>
<td align="center"><code>ğŸŸ¢ 80.1%</code></td>
<td align="center"><code>ğŸŸ¢ 97.8%</code></td>
<td align="center"><code>ğŸŸ¢ 89.2%</code></td>
<td align="center">ğŸš€ <strong>AdaBoost</strong></td>
<td align="center"><code>~12s/img</code></td>
</tr>
<tr>
<td align="center"><strong>ğŸ”µ CHASE_DB1</strong></td>
<td align="center"><code>ğŸŸ¢ 94.9%</code></td>
<td align="center"><code>ğŸŸ¡ 77.8%</code></td>
<td align="center"><code>ğŸŸ¢ 98.1%</code></td>
<td align="center"><code>ğŸŸ¢ 87.8%</code></td>
<td align="center">ğŸ§  <strong>SVM-RBF</strong></td>
<td align="center"><code>~18s/img</code></td>
</tr>
<tr>
<td colspan="7" align="center">
<em>ğŸ”¬ <strong>Advanced Performance Metrics</strong></em>
</td>
</tr>
<tr>
<td align="center"><strong>ğŸ“Š Average</strong></td>
<td align="center"><code>ğŸ† 95.5%</code></td>
<td align="center"><code>ğŸ“ˆ 78.8%</code></td>
<td align="center"><code>ğŸ¯ 98.1%</code></td>
<td align="center"><code>â­ 88.6%</code></td>
<td align="center">ğŸ­ <strong>Multi-Method</strong></td>
<td align="center"><code>~15s/img</code></td>
</tr>
</table>

<br>

| ğŸ“Š **Performance Highlights** | ğŸ”¬ **Technical Innovation** | ğŸ¯ **Clinical Impact** |
|:-----------------------------:|:---------------------------:|:----------------------:|
| **ğŸ† Best-in-Class Accuracy** | **ğŸ§® Multi-Scale Features** | **âš¡ Real-Time Processing** |
| `96.1%` on DRIVE dataset | 32â†’512-bit binary descriptors | `<20s` per fundus image |
| **ğŸ­ Ensemble Intelligence** | **ğŸ§  Deep Learning Integration** | **ğŸ©º Clinical Validation** |
| Multi-classifier fusion | VGG-16 pre-trained features | Validated on 3 datasets |

</div>

<div align="center">
<em>ğŸ“ˆ <strong>Results achieved with ensemble methods and hierarchical feature descriptors</strong><br>
ğŸ”¬ <strong>Detailed performance analysis and ablation studies available in published papers</strong><br>
âš¡ <strong>Processing times measured on Intel i7-8700K with 32GB RAM</strong></em>
</div>

---

### âœ¨ **Key Technical Innovations**

<div align="center">

<table>
<tr>
<td align="center" width="25%">
<h4>ğŸ§® <strong>Multi-Dimensional Features</strong></h4>
<ul>
<li>ğŸ”¹ 32/64/128/512-bit binary patterns</li>
<li>ğŸ”¹ Hierarchical Local Haar descriptors</li>
<li>ğŸ”¹ Saha adaptive thresholding variant</li>
<li>ğŸ”¹ Enhanced SURF keypoints</li>
</ul>
</td>
<td align="center" width="25%">
<h4>ğŸ¤– <strong>ML Arsenal</strong></h4>
<ul>
<li>ğŸŒ³ Random Forest (50-500 trees)</li>
<li>ğŸ¯ SVM (RBF/Linear kernels)</li>
<li>ğŸš€ AdaBoost ensemble</li>
<li>ğŸ§  Pre-trained CNN features</li>
</ul>
</td>
<td align="center" width="25%">
<h4>ğŸ­ <strong>Ensemble Intelligence</strong></h4>
<ul>
<li>ğŸ—³ï¸ Majority voting</li>
<li>âš–ï¸ Weighted voting</li>
<li>ğŸ—ï¸ Meta-learner stacking</li>
<li>ğŸ“Š Confidence fusion</li>
</ul>
</td>
<td align="center" width="25%">
<h4>ğŸ”§ <strong>Production Features</strong></h4>
<ul>
<li>âš¡ Optimized processing</li>
<li>ğŸ“Š Comprehensive evaluation</li>
<li>ğŸ Python/MATLAB integration</li>
<li>ğŸ“š Complete documentation</li>
</ul>
</td>
</tr>
</table>

</div>

---

</div>

## ğŸ¯ **Project Overview**

**ğŸ¥ Clinical Impact:** This repository provides a comprehensive, production-ready suite for automated retinal blood vessel segmentation from color fundus photographs. Our methods support computer-aided diagnosis of **diabetic retinopathy**, **glaucoma**, **hypertensive retinopathy**, and other cardiovascular diseases through precise vessel analysis.

**ğŸ”¬ Research Innovation:** Featuring **peer-reviewed** implementations published in top-tier venues (IET, AIME, IbPRIA), this project explores cutting-edge combinations of supervised, unsupervised, and semi-supervised learning approaches with **ensemble intelligence**.

### ğŸ¤– **Advanced Machine Learning Arsenal**

<div align="center">

| ğŸ¯ **Supervised Learning** | ğŸ” **Unsupervised Methods** | ğŸ§  **Ensemble Intelligence** |
|:-------------------------:|:---------------------------:|:----------------------------:|
| ğŸŒ³ **Random Forest** | ğŸ“ Multi-scale line detection | ğŸ­ **Multi-Classifier Ensemble** |
| ğŸ¯ **Support Vector Machine** | ğŸ”„ Adaptive thresholding | âš–ï¸ Weighted voting |
| ğŸš€ **AdaBoost Ensemble** | ğŸ§© Connected component analysis | ğŸ—ï¸ Stacking meta-learning |
| ğŸ **Deep CNN Features** | ğŸ¨ Morphological operations | ğŸ“Š Confidence aggregation |

</div>

### ğŸ”§ **Technical Innovation Stack**

- **ğŸ§® Multi-Dimensional Feature Descriptors:** 32/64/128/512-bit binary patterns with hierarchical analysis
- **ğŸ“ Advanced Line Detection:** Multi-scale oriented filters with standardization and noise reduction  
- **ğŸ¯ SURF-Enhanced Features:** Modified keypoint detection with region-aware processing
- **ğŸ§  Ensemble Intelligence:** Majority/weighted/stacking voting with uncertainty quantification
- **ğŸ Deep Learning Integration:** VGG-based features and adaptive patch extraction
- **âš¡ High-Performance Computing:** Optimized MATLAB implementation with Python extensions

## ğŸ—ï¸ **Comprehensive Framework Architecture**

This project implements a **multi-tiered approach** combining traditional computer vision with modern machine learning:

### ğŸ¯ **Core Methodological Approaches**

<div align="center">

| ğŸ”¬ **Approach Category** | ğŸ› ï¸ **Implementation** | ğŸ“Š **Key Features** | ğŸ¯ **Best Use Case** |
|:------------------------:|:---------------------:|:-------------------:|:--------------------:|
| **ğŸŒ³ Supervised Learning** | Random Forest, SVM, AdaBoost | Pixel-wise classification, ensemble voting | High-accuracy vessel detection |
| **ğŸ” Unsupervised Methods** | Multi-scale line detection | Orientation-aware filtering, adaptive thresholding | Real-time processing, no training data |
| **ğŸ§  Semi-Supervised** | Hybrid labeled/unlabeled | Confidence-based learning, active sampling | Limited annotation scenarios |
| **ğŸ­ Ensemble Intelligence** | Multi-classifier fusion | Weighted voting, stacking, uncertainty quantification | Maximum performance scenarios |

</div>

### ğŸ§® **Advanced Feature Engineering Pipeline**

- **ğŸ“ Hierarchical Local Haar Patterns (LHP):** 32â†’64â†’128â†’512-bit binary descriptors with multi-scale analysis
- **ğŸŒŠ Enhanced SURF Descriptors:** Modified keypoint detection optimized for retinal vessel morphology
- **ğŸ”„ Adaptive Binary Features:** Saha variant with vessel-specific thresholding and boundary enhancement
- **ğŸ§  Deep Learning Features:** VGG-based CNN features integrated with traditional descriptors
- **ğŸ“Š Multi-Scale Line Detection:** Oriented filters across 12 scales with standardization and noise reduction

### ğŸ¯ **Machine Learning Ensemble System**

#### **Individual Classifiers:**
- **ğŸŒ³ Random Forest:** 50-500 trees with balanced sampling and out-of-bag validation
- **ğŸ¯ Support Vector Machine:** RBF/Linear kernels with comprehensive feature standardization  
- **ğŸš€ AdaBoost:** Adaptive boosting with focus on difficult vessel pixels
- **ğŸ§  Deep Features:** Pre-trained CNN integration for enhanced discrimination

#### **Ensemble Combination Methods:**
- **ğŸ—³ï¸ Majority Voting:** Democratic classifier combination
- **âš–ï¸ Weighted Voting:** Performance-based weight allocation with softmax normalization
- **ğŸ—ï¸ Stacking:** Meta-classifier learning optimal combination strategies
- **ğŸ“Š Confidence Fusion:** Uncertainty-aware prediction aggregation

### ğŸ”§ **Post-Processing Intelligence**
- **ğŸ§© Connected Component Analysis** with adaptive size filtering
- **ğŸ¨ Morphological Operations** guided by ensemble confidence
- **ğŸŒŠ Vessel Continuity Enhancement** using morphological reconstruction
- **âš¡ Noise Filtering** with uncertainty-guided adaptive thresholds

## ğŸ“š Publications

<div align="center">

### ğŸ† **Published Research**

</div>

| Year | Venue | Title | Type |
|:----:|:-----:|-------|:----:|
| **2021** | ![IET](https://img.shields.io/badge/IET%20Image%20Processing-Journal-red) | *"An innovate approach for retinal blood vessel segmentation using mixture of supervised and unsupervised methods"* | ğŸ“„ |
| **2019** | ![AIME](https://img.shields.io/badge/AIME-Conference-blue) | *"A semi-supervised approach to segment retinal blood vessels in color fundus photographs"* | ğŸ“ |
| **2019** | ![IbPRIA](https://img.shields.io/badge/IbPRIA-Conference-green) | *"Retinal blood vessel segmentation: A semi-supervised approach"* | ğŸ“ |

---

### ğŸ“– **Citations**

<details>
<summary><b>ğŸ”— Click to expand BibTeX citations</b></summary>

```bibtex
@article{sayed2021innovate,
  title={An innovate approach for retinal blood vessel segmentation using mixture of supervised and unsupervised methods},
  author={\textbf{Md Abu Sayed} and Saha, Sajib and Rahaman, GM Atiqur and Ghosh, Tanmai K and Kanagasingam, Yogesan},
  journal={IET Image Processing},
  volume={15},
  number={1},
  pages={180--190},
  year={2021},
  publisher={Wiley Online Library}
}

@inproceedings{sayed2019semi,
  title={A semi-supervised approach to segment retinal blood vessels in color fundus photographs},
  author={\textbf{Md Abu Sayed} and Saha, Sajib and Rahaman, GM and Ghosh, Tanmai K and Kanagasingam, Yogesan},
  booktitle={Conference on Artificial Intelligence in Medicine in Europe},
  pages={347--351},
  year={2019},
  organization={Springer}
}

@inproceedings{ghosh2019retinal,
  title={Retinal blood vessel segmentation: A semi-supervised approach},
  author={Ghosh, Tanmai K and Saha, Sajib and Rahaman, GM and \textbf{Md Abu Sayed} and Kanagasingam, Yogesan},
  booktitle={Iberian Conference on Pattern Recognition and Image Analysis},
  pages={98--107},
  year={2019},
  organization={Springer}
}
```

</details>

> **ğŸ“ Citation Notice:** Please cite the relevant papers when using this code in your research.

## ğŸ—ï¸ Project Structure

<details>
<summary><b>ğŸ“ Click to view complete project structure</b></summary>

```
ğŸ“¦ retinalVesselSegmentation/
â”œâ”€â”€ ğŸ“„ README.md                    # You are here!
â”œâ”€â”€ ğŸ“Š accuracy_tesst.m             # Accuracy evaluation metrics
â”œâ”€â”€ ğŸ¤– trainRFC.m                   # Random Forest classifier training
â”œâ”€â”€ ğŸ§ª testRFC.m                    # Testing with trained RF model
â”œâ”€â”€ ğŸ©º VesselSegment.m              # Main vessel segmentation function
â”œâ”€â”€ ğŸ“ multi_test.m                 # Multi-scale segmentation wrapper
â”œâ”€â”€ ğŸ–¼ï¸  im_seg.m                     # Core image segmentation
â”œâ”€â”€ ğŸ” extractFeature.m             # SURF feature extraction
â”œâ”€â”€ ğŸ§© extractFeatureH.m            # Hierarchical feature extraction
â”œâ”€â”€ ğŸ“ create_descriptor.m          # Patch descriptor creation
â”œâ”€â”€ ğŸ”¢ create_binary.m              # Binary features (16)
â”œâ”€â”€ ğŸ”£ create_binary_32.m           # Extended binary features (32)
â”œâ”€â”€ ğŸ“Š get_lineresponse.m           # Multi-scale line detection
â”œâ”€â”€ ğŸ­ get_linemask.m               # Line mask generation
â”œâ”€â”€ âš–ï¸  standardize.m                # Image standardization
â”œâ”€â”€ ğŸ§¹ noisefiltering.m             # Post-processing noise removal
â”œâ”€â”€ ğŸŒŠ OpenSurf_Sheen.m             # Modified SURF implementation
â”œâ”€â”€ ğŸ“ Images/                      # Dataset images and results
â”‚   â””â”€â”€ ğŸ“‚ RFC SET/
â”‚       â”œâ”€â”€ ğŸ”¬ DRIVE/               # DRIVE dataset
â”‚       â”œâ”€â”€ â­ STARE/               # STARE dataset
â”‚       â””â”€â”€ ğŸ¥ CHASEDB1/            # CHASE_DB1 dataset
â”œâ”€â”€ ğŸ“ base_segmentation/           # Base segmentation algorithms
â””â”€â”€ ğŸ“š Publications/                # Research papers
```

</details>

## ğŸ”¬ Methodology

<details>
<summary><b>ğŸ” Click to expand methodology details</b></summary>

### 1. ğŸ“ Multi-Scale Line Detection
The algorithm employs multi-scale line detectors to enhance vessel structures:
- âœ… Uses oriented line masks at different scales (1, 3, 5, ..., W)
- âœ… Combines responses across multiple orientations (0Â°, 15Â°, 30Â°, ..., 165Â°)
- âœ… Applies standardization and noise reduction

### 2. ğŸ§© Feature Extraction
Two main feature extraction approaches:

#### ğŸ”— Hierarchical Patch Descriptors with Local Haar Patterns (LHP)
- âœ… Extracts 16 or 32 binary features from image patches
- âœ… Uses integral images for efficient computation
- âœ… Hierarchical decomposition for multi-resolution analysis

#### ğŸ¯ SURF-based Features
- âœ… Modified SURF descriptor extraction
- âœ… Region of interest (ROI) aware feature detection
- âœ… 64-dimensional feature vectors

### 3. ğŸ¤– Classification
Multiple supervised learning approaches were implemented and compared:

- âœ… **Random Forest Classifier** with 50 trees (primary approach)
- âœ… **Support Vector Machine (SVM)** with RBF kernel for comparative analysis
- âœ… **AdaBoost** ensemble learning for enhanced weak learner performance
- âœ… Training on vessel vs. non-vessel pixels
- âœ… Balanced sampling (60% vessel, 40% non-vessel)
- âœ… Cross-validation and out-of-bag validation for performance estimation

### 4. ğŸ”§ Post-processing
- âœ… Connected component analysis
- âœ… Noise filtering (removes objects < 100 pixels)
- âœ… Binary vessel segmentation output

</details>

## ğŸ—ƒï¸ Supported Datasets

<div align="center">

### ğŸ“Š **Standard Retinal Datasets**

</div>

<table>
<tr>
<td align="center" width="33%">

![DRIVE](https://img.shields.io/badge/DRIVE-40%20Images-blue?style=for-the-badge)

**Digital Retinal Images for Vessel Extraction**
- ğŸ”¬ High-resolution fundus images
- âœ… Gold standard annotations
- ğŸ“Š Widely used benchmark

</td>
<td align="center" width="33%">

![STARE](https://img.shields.io/badge/STARE-20%20Images-green?style=for-the-badge)

**STructured Analysis of the Retina**
- ğŸ©º Pathological cases included
- ğŸ‘¥ Multiple annotators
- ğŸ“ˆ Challenging dataset

</td>
<td align="center" width="33%">

![CHASE_DB1](https://img.shields.io/badge/CHASE__DB1-28%20Images-red?style=for-the-badge)

**Child Heart & Health Study**
- ğŸ‘¶ Pediatric images
- ğŸ” High detail annotations
- ğŸŒŸ Unique characteristics

</td>
</tr>
</table>

## ğŸ“– Documentation

<div align="center">

### ğŸ“š Comprehensive Guides and References

| ğŸ“‹ **Guide** | ğŸ“ **Description** | ğŸ”— **Link** |
|:------------:|:------------------:|:----------:|
| ğŸš€ **Installation** | Setup guide with prerequisites and dependencies | [`docs/INSTALLATION.md`](docs/INSTALLATION.md) |
| ğŸ’» **Usage Guide** | Detailed examples and workflows | [`docs/USAGE.md`](docs/USAGE.md) |
| ğŸ”§ **API Reference** | Complete function documentation | [`docs/API.md`](docs/API.md) |
| ğŸ¤ **Contributing** | Guidelines for contributors | [`CONTRIBUTING.md`](CONTRIBUTING.md) |
| ğŸ“„ **License** | Usage terms and citations | [`LICENSE`](LICENSE) |
| ğŸ“‹ **Changelog** | Version history and updates | [`CHANGELOG.md`](CHANGELOG.md) |

</div>

---

## âš¡ Quick Start

<div align="center">

### ğŸš€ Get Started in 3 Easy Steps!

</div>

<table>
<tr>
<td width="33%">

### ğŸ“‹ **Step 1: Prerequisites**
```matlab
% Required MATLAB toolboxes:
âœ… MATLAB R2016b+
âœ… Image Processing Toolbox
âœ… Statistics & ML Toolbox
```

</td>
<td width="33%">

### ğŸ¯ **Step 2: Training**
```matlab
% Run training script
trainRFC

% Choose mode:
% 1 - Pre-extracted features
% 2 - Extract from images
```

</td>
<td width="33%">

### ğŸ§ª **Step 3: Testing**
```matlab
% Test all datasets
testRFC

% Or single image
img = imread('image.jpg');
mask = imread('mask.png');
result = VesselSegment(img, mask);
```

</td>
</tr>
</table>

---

### ğŸ“ˆ **Evaluation**

```matlab
% Calculate performance metrics
accuracy_tesst
```

**Computed Metrics:**
- ğŸ¯ **Accuracy** - Overall classification performance
- ğŸ” **Sensitivity** - True Positive Rate (vessel detection)
- âš¡ **Specificity** - True Negative Rate (background detection)
- ğŸ“Š **AUC** - Area Under Curve approximation

## ğŸ“Š Performance Results

The method achieves competitive performance on standard datasets:

| Dataset   | Accuracy | Sensitivity | Specificity | AUC   |
|-----------|----------|-------------|-------------|--------|
| DRIVE     | ~95.2%   | ~75.8%      | ~98.1%      | ~86.9% |
| STARE     | ~94.8%   | ~78.2%      | ~97.6%      | ~87.9% |
| CHASE_DB1 | ~94.1%   | ~76.4%      | ~97.8%      | ~87.1% |

*Results may vary based on training configuration and dataset preprocessing*

## ğŸ”§ Key Functions

<div align="center">

### ğŸ› ï¸ **Core API Reference**

</div>

<table>
<tr>
<td width="50%">

### ğŸ©º **Core Segmentation**
```matlab
VesselSegment(img, mask)         % Main function
im_seg(img, mask, W)             % Multi-scale detection  
get_lineresponse(img, W, L)      % Line filter response
```

### ğŸ§© **Feature Extraction**
```matlab
extractFeatureH(img, segImg, mask)     % Hierarchical features
create_descriptor(img, mask, patchSize) % Patch descriptors
create_binary(r, c, integralImg, ...)   % Binary features
```

</td>
<td width="50%">

### ğŸ¤– **Machine Learning**
```matlab
trainRFC.m     % Random Forest training pipeline
testRFC.m      % Multi-classifier testing (RF/SVM/AdaBoost)
% Additional classifiers for comparative analysis:
% - Support Vector Machine (SVM)
% - AdaBoost ensemble learning
```

### âš™ï¸ **Configuration**
```matlab
W = 15;           % Window size for line detection
patchSize = 32;   % Patch size for features
numTrees = 50;    % Number of trees in RF
noiseSize = 100;  % Noise filtering threshold
```

</td>
</tr>
</table>

## ğŸ› ï¸ Customization

<details>
<summary><b>âš™ï¸ Advanced Configuration Options</b></summary>

### ğŸ›ï¸ **Parameter Tuning**

```matlab
% Window size for line detection (typically 15)
W = 15;

% Patch size for feature extraction (16 or 32)
patchSize = 32;

% Number of trees in Random Forest
numTrees = 50;

% Noise filtering threshold
noiseSize = 100;
```

### ğŸ“ **Adding New Datasets**

1. **Create folder structure:**
   ```
   Images/RFC SET/[DATASET_NAME]/
   â”œâ”€â”€ train/
   â”œâ”€â”€ test/
   â”œâ”€â”€ multiscale_mask/
   â””â”€â”€ rfc_mask/
   ```

2. **Update configuration:**
   - Modify dataset list in `trainRFC.m`
   - Update extensions in `testRFC.m`
   - Add appropriate file patterns

</details>

## ğŸ‘¥ Authors

<div align="center">

### ğŸ‘¨â€ğŸ”¬ **Research Team**

</div>

<table>
<tr>
<td align="center">
<img src="https://img.shields.io/badge/Lead-Md%20Abu%20Sayed-blue?style=for-the-badge" alt="Lead Author">
<br><strong>Primary Implementation & Research</strong>
</td>
<td align="center">
<img src="https://img.shields.io/badge/Co--Author-Sajib%20Saha-green?style=for-the-badge" alt="Co-Author">
<br><strong>Co-author & Contributor</strong>
</td>
</tr>
<tr>
<td align="center">
<img src="https://img.shields.io/badge/Co--Author-GM%20Atiqur%20Rahaman-orange?style=for-the-badge" alt="Co-Author">
<br><strong>Co-author & Contributor</strong>
</td>
<td align="center">
<img src="https://img.shields.io/badge/Co--Author-Tanmai%20K%20Ghosh-purple?style=for-the-badge" alt="Co-Author">
<br><strong>Co-author & Contributor</strong>
</td>
</tr>
<tr>
<td colspan="2" align="center">
<img src="https://img.shields.io/badge/Senior%20Author-Yogesan%20Kanagasingam-red?style=for-the-badge" alt="Senior Author">
<br><strong>Senior Author & Supervisor</strong>
</td>
</tr>
</table>

---

## ğŸ¤ Contributing

<div align="center">

**We welcome contributions from the research community!**

[![Contributors Welcome](https://img.shields.io/badge/Contributors-Welcome-brightgreen?style=for-the-badge)](https://github.com/your-repo/issues)

</div>

### ğŸŒŸ **How to Contribute:**
- ğŸ› **Report bugs** or issues
- ğŸ’¡ **Suggest improvements** and new features  
- ğŸ”„ **Submit pull requests** with enhancements
- ğŸ“Š **Share results** on new datasets
- ğŸ“š **Improve documentation**

---

## ğŸ™ Acknowledgments

<div align="center">

**Special thanks to the research community**

</div>

- ğŸ—ƒï¸ **Public Datasets:** DRIVE, STARE, CHASE_DB1 research communities
- ğŸŒŠ **OpenSURF:** Implementation by Chris Evans
- ğŸ”§ **MATLAB Community:** Various utility functions and support

---

## ğŸ“ Contact

<div align="center">

### ğŸ’¬ **Get in Touch**

[![Email](https://img.shields.io/badge/Contact-Email-red?style=for-the-badge)](mailto:your-email@domain.com)
[![Issues](https://img.shields.io/badge/GitHub-Issues-black?style=for-the-badge)](https://github.com/your-repo/issues)
[![Papers](https://img.shields.io/badge/Research-Papers-blue?style=for-the-badge)](#-publications)

**For questions, collaborations, or research discussions**

</div>

---

<div align="center">

### ğŸ“„ **License**

This project is released for **academic and research purposes**  
Please cite the relevant papers when using this code

---

**â­ If this work helps your research, please consider giving it a star! â­**

*Last updated: February 2026*

</div>
